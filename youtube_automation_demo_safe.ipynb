{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a09598c",
   "metadata": {},
   "source": [
    "# AI Content Automation Pipeline ‚Äî Demo Version\n",
    "This notebook is a sanitized public demo. Sensitive logic, prompts, credentials, and third‚Äëparty integrations have been removed or abstracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be590323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('/content/drive/MyDrive'):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"‚úÖ Drive already mounted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install external_service moviepy gspread oauth2client requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import external_service as mp\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from external_service import external_service\n",
    "from google.colab import drive\n",
    "from external_service import external_service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# PATHS\n",
    "# -------------------------\n",
    "drive_root = \"/content/drive/MyDrive/external_service\"\n",
    "script_folder = os.path.join(drive_root, \"script\")\n",
    "rtf_file = os.path.join(script_folder, \"script_22.txt\")\n",
    "output_csv = os.path.join(script_folder, \"script_chunks.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# LOAD FILE\n",
    "# -------------------------\n",
    "if not os.path.exists(rtf_file):\n",
    "    raise FileNotFoundError(\"‚ùå script_22.txt not found in script folder\")\n",
    "\n",
    "with open(rtf_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# -------------------------\n",
    "# CLEAN RTF (remove tags)\n",
    "# -------------------------\n",
    "clean_text = re.sub(r\"{\\\\.*?}|\\\\[A-Za-z]+\\d*|[{}]\", \"\", content)\n",
    "clean_text = re.sub(r\"\\s+\", \" \", clean_text).strip()\n",
    "\n",
    "# -------------------------\n",
    "# FIX: Replace semicolons so CSV does NOT break\n",
    "# -------------------------\n",
    "clean_text = clean_text.replace(\";\", \".\")   # <--- important fix\n",
    "\n",
    "# -------------------------\n",
    "# SPLIT INTO SENTENCES\n",
    "# -------------------------\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', clean_text)\n",
    "sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
    "\n",
    "print(\"üìå Total sentences:\", len(sentences))\n",
    "\n",
    "# -------------------------\n",
    "# CHUNKING WITH MIN 30 WORDS\n",
    "# -------------------------\n",
    "chunks = []\n",
    "i = 0\n",
    "\n",
    "while i < len(sentences):\n",
    "    # Start with 2 sentences\n",
    "    current_chunk = sentences[i:i+2]\n",
    "    combined = \" \".join(current_chunk)\n",
    "\n",
    "    # Ensure >= 18 words (your original logic)\n",
    "    while len(combined.split()) < 25 and (i + len(current_chunk)) < len(sentences):\n",
    "        current_chunk.append(sentences[i + len(current_chunk)])\n",
    "        combined = \" \".join(current_chunk)\n",
    "\n",
    "    chunks.append(combined)\n",
    "    i += len(current_chunk)\n",
    "\n",
    "print(\"üìå Total chunks created:\", len(chunks))\n",
    "\n",
    "# -------------------------\n",
    "# SAVE TO CSV\n",
    "# -------------------------\n",
    "df = pd.DataFrame({\"chunk\": chunks})\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Chunk CSV saved at:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# CONFIG\n",
    "# ================================================\n",
    "SPREADSHEET_ID = \"1eNcH6DKc4N4pvS8Rmy3ZdsrOR6RcYzzwkYXop0Noi7A\"\n",
    "\n",
    "# ================================================\n",
    "# LOAD GOOGLE SHEET DIRECTLY\n",
    "# ================================================\n",
    "csv_url = f\"https://example.com/api\"\n",
    "\n",
    "df = pd.read_csv(csv_url)\n",
    "script_chunks = df.iloc[:, 0].tolist()\n",
    "\n",
    "print(\"Loaded\", len(script_chunks), \"script chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "#  CONFIG\n",
    "# ================================================\n",
    "\n",
    "external_service_REDACTED_SECRET = 'REMOVED_FOR_PUBLIC_RELEASE'\n",
    "LEONARDO_REDACTED_SECRET = 'REMOVED_FOR_PUBLIC_RELEASE'\n",
    "\n",
    "client = external_service(api_key=external_service_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICEOVER_FOLDER = \"/content/drive/MyDrive/external_service/voice/\"\n",
    "FINAL_VIDEO = \"/content/drive/MyDrive/external_service/Video/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from external_service import external_service\n",
    "\n",
    "# ================================================\n",
    "# üî• LOAD ENTIRE SCRIPT AS CONTEXT MEMORY\n",
    "# ================================================\n",
    "def build_script_memory(sentences):\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "# ================================================\n",
    "# üé® RANDOM CINEMATIC VARIATION BOOSTER\n",
    "# (added to enforce unique images)\n",
    "# ================================================\n",
    "def random_visual_style():\n",
    "    styles = [\n",
    "        \"XXXXXXXXXXXXXXXXXX\"\n",
    "    ]\n",
    "    return \", \".join(random.sample(styles, 3))\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# ‚ö° FIXED + UPGRADED: Generate mythology prompt\n",
    "# ================================================\n",
    "def create_prompt(text, full_script_memory):\n",
    "    system_prompt = \"USER_DEFINED_PROMPT_OMITTED\"\"\n",
    "You generate cinematic mythology-style image descriptions SAFE for Leonardo AI.\n",
    "\n",
    "\n",
    "\n",
    "    # üé® NEW: Variation injected here\n",
    "    variation = random_visual_style()\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Convert the SCRIPT CHUNK into a visually rich, mythology-style image prompt.\n",
    "\n",
    "### VISUAL VARIATION TO APPLY FOR THIS IMAGE:\n",
    "{variation}\n",
    "\n",
    "FULL SCRIPT CONTEXT (reference only):\n",
    "{full_script_memory}\n",
    "\n",
    "SCRIPT CHUNK (actual content to convert):\n",
    "{text}\n",
    "\n",
    "Return only the final image prompt.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"external_service-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.95,      # üî• Increased creativity\n",
    "        max_tokens=250\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD SCRIPT MEMORY (uses the same sentences from your chunking code)\n",
    "# ============================================================\n",
    "full_script_memory = build_script_memory(sentences)\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE PROMPTS FOR EACH CHUNK\n",
    "# ============================================================\n",
    "prompts = []\n",
    "\n",
    "for text in df.iloc[:, 0]:   # assuming script chunks are in column A\n",
    "    if str(text).strip() == \"\":\n",
    "        prompts.append(\"\")\n",
    "        continue\n",
    "\n",
    "    # pass both required arguments\n",
    "    prompt_out = create_prompt(str(text), full_script_memory)\n",
    "    prompts.append(prompt_out)\n",
    "\n",
    "df[\"prompt_generated\"] = prompts\n",
    "\n",
    "print(\"‚úÖ Prompts generated for all rows!\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/content/drive/MyDrive/external_service/script/script_chunks_with_prompts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940bd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_folder = \"/content/drive/MyDrive/external_service/image/\"\n",
    "os.makedirs(image_folder, exist_ok=True)   # creates folder if not exists\n",
    "\n",
    "print(\"‚úÖ Image folder ready:\", image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fish Audio TTS ‚Äì Deep Story by Moses Nwosah, High Quality, Separate Chunks\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# -------------------------------\n",
    "# PATHS\n",
    "# -------------------------------\n",
    "drive_root = \"/content/drive/MyDrive/external_service\"\n",
    "voice_folder = os.path.join(drive_root, \"voice\")\n",
    "os.makedirs(voice_folder, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD GOOGLE SHEET\n",
    "# -------------------------------\n",
    "file_id = \"12oIWWen6aRBInJuyVrLDHlcmQ5gx7Mxt\"\n",
    "sheet_url = f\"https://example.com/api\"\n",
    "\n",
    "df = pd.read_csv(sheet_url)\n",
    "\n",
    "if \"chunk\" not in df.columns:\n",
    "    raise ValueError(\"‚ùå 'chunk' column not found in Google Sheet\")\n",
    "\n",
    "print(f\"üìå Loaded {len(df)} chunks from Google Sheet\")\n",
    "\n",
    "# -------------------------------\n",
    "# FISH AUDIO SETTINGS\n",
    "# -------------------------------\n",
    "REDACTED_SECRET = 'REMOVED_FOR_PUBLIC_RELEASE'\n",
    "REFERENCE_ID = \"XXXXXXXXXXX\" \n",
    "MODEL = \"XXX\"  \n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "url = \"https://example.com/api\"\n",
    "\n",
    "# -------------------------------\n",
    "# GENERATE VOICE (ONE FILE PER CHUNK)\n",
    "# -------------------------------\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    text = str(row[\"chunk\"]).strip()\n",
    "\n",
    "    if len(text) < 2:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty chunk at row {index+1}\")\n",
    "        continue\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"reference_id\": REFERENCE_ID,\n",
    "        \"format\": \"mp3\",\n",
    "        \"text\": text,\n",
    "\n",
    "        # Cinematic pacing\n",
    "        \"speed\": 0.88,          # slower narration\n",
    "        \"temperature\": 0.9,\n",
    "        \"top_p\": 0.9,\n",
    "\n",
    "        # Audio quality\n",
    "        \"audio_quality\": \"high\",\n",
    "        \"silence\": 0.28,        # slightly longer pauses\n",
    "        \"normalize\": False\n",
    "    }\n",
    "\n",
    "    print(f\"üé§ Generating voiceover for chunk {index + 1}‚Ä¶\")\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        output_path = os.path.join(voice_folder, f\"chunk_{index+1}.mp3\")\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"‚úÖ Saved chunk_{index+1}.mp3\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error for chunk {index+1}: {response.text}\")\n",
    "\n",
    "print(\"‚öîÔ∏è All Deep Story voices generated successfully ‚Äî exactly like UI sample!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install moviepy pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b86ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a77c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# FINAL CINEMATIC PIPELINE ‚Äî OPTION A (BEST FOR external_service VOICE SYNC)\n",
    "# Perfect synced voice ‚Üí images match exactly ‚Üí clean fades\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from external_service import (\n",
    "    ImageClip, VideoFileClip, AudioFileClip,\n",
    "    CompositeVideoClip, CompositeAudioClip,\n",
    "    concatenate_videoclips, concatenate_audioclips, VideoClip, AudioClip\n",
    ")\n",
    "from moviepy.video.fx import all as vfx\n",
    "from moviepy.audio.fx.all import audio_fadein, audio_fadeout\n",
    "from proglog import ProgressBarLogger\n",
    "from natsort import natsorted\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --------------------------\n",
    "# PATHS\n",
    "# --------------------------\n",
    "drive_root = \"/content/drive/MyDrive/external_service\"\n",
    "image_folder = os.path.join(drive_root, \"image\")\n",
    "voice_folder = os.path.join(drive_root, \"voice\")\n",
    "bg_folder = os.path.join(drive_root, \"bgvoice\")\n",
    "effect_folder = os.path.join(drive_root, \"effect\")\n",
    "output_folder = os.path.join(drive_root, \"Video\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, \"final_video.mp4\")\n",
    "\n",
    "TARGET_RES = (1920, 1080)\n",
    "THREADS = 4\n",
    "\n",
    "MOTION_BLUR_STRENGTH = 0.6\n",
    "GRAIN_INTENSITY = 0.03\n",
    "DEPTH_PARALLAX_DURATION = 180.0\n",
    "DEPTH_PARALLAX_STRENGTH = 22\n",
    "COLOR_GRADE_STRENGTH = 0.18\n",
    "SUBTLE_CONTRAST = 1.03\n",
    "\n",
    "FADE_DURATION = 0.6  # fade between images (NO overlap)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# LOAD FILES\n",
    "# --------------------------\n",
    "def sorted_files(folder, exts):\n",
    "    if not os.path.exists(folder):\n",
    "        return []\n",
    "    return natsorted([os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(exts)])\n",
    "\n",
    "images = sorted_files(image_folder, (\".png\", \".jpg\", \".jpeg\"))\n",
    "voice_files = sorted_files(voice_folder, (\".mp3\", \".wav\", \".m4a\", \".mp4\"))\n",
    "bg_files = sorted_files(bg_folder, (\".mp3\", \".wav\"))\n",
    "\n",
    "if not images: raise FileNotFoundError(\"No images found.\")\n",
    "if not voice_files: raise FileNotFoundError(\"No voice files found.\")\n",
    "if not bg_files: raise FileNotFoundError(\"No background music found.\")\n",
    "\n",
    "print(f\"Found {len(images)} images, {len(voice_files)} voice chunks.\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# LOAD OPTIONAL PARTICLES\n",
    "# --------------------------\n",
    "# particle_path = os.path.join(effect_folder, \"particle.mp4\")\n",
    "# particle_base = None\n",
    "# if os.path.exists(particle_path):\n",
    "#     try:\n",
    "#         particle_base = VideoFileClip(particle_path)\n",
    "#         print(\"Loaded particle effect.\")\n",
    "#     except:\n",
    "#         particle_base = None\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# STEP 1 ‚Äî COMBINE ALL VOICE CHUNKS INTO ONE PERFECT VOICE TRACK\n",
    "# ================================================================\n",
    "print(\"\\nüîä Combining all voice chunks...\")\n",
    "\n",
    "raw_voices = [AudioFileClip(v) for v in voice_files]\n",
    "voice_durations = [v.duration for v in raw_voices]\n",
    "\n",
    "processed_voices = [\n",
    "    v.fx(audio_fadein, FADE_DURATION)\n",
    "     .fx(audio_fadeout, FADE_DURATION)\n",
    "    for v in raw_voices\n",
    "]\n",
    "\n",
    "full_voice = concatenate_audioclips(processed_voices)\n",
    "print(\"Voice track combined.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def particle_fx_for_duration(duration):\n",
    "#     if particle_base is None:\n",
    "#         return None\n",
    "#     if particle_base.duration < duration:\n",
    "#         loops = int(duration // particle_base.duration) + 1\n",
    "#         return concatenate_videoclips([particle_base]*loops).subclip(0, duration).resize(TARGET_RES)\n",
    "#     return particle_base.subclip(0, duration).resize(TARGET_RES)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# STEP 2 ‚Äî BUILD CLIPS WITHOUT AUDIO (SYNC FROM VOICE DURATIONS)\n",
    "# ================================================================\n",
    "depth_counter = 0\n",
    "\n",
    "def build_clip_for_image(args):\n",
    "    image_path, idx = args\n",
    "    duration = voice_durations[idx]\n",
    "\n",
    "    img = load_and_fill_image(image_path)\n",
    "    use_depth = depth_counter < DEPTH_PARALLAX_DURATION\n",
    "\n",
    "    if use_depth:\n",
    "        clip = apply_depth_parallax(img, duration)\n",
    "    else:\n",
    "        clip = ImageClip(img).set_duration(duration)\n",
    "\n",
    "    # Cinematic motions\n",
    "    zoom_s = random.uniform(1.06,1.09)\n",
    "    zoom_e = random.uniform(1.10,1.14)\n",
    "    pan_x = random.uniform(-0.02,0.02)*TARGET_RES[0]\n",
    "    pan_y = random.uniform(-0.02,0.02)*TARGET_RES[1]\n",
    "    rot = random.uniform(-0.6,0.6)\n",
    "\n",
    "    clip = (\n",
    "        clip.resize(lambda t: zoom_s + (zoom_e-zoom_s)*(t/duration))\n",
    "            .set_position(lambda t: (pan_x*(t/duration), pan_y*(t/duration)))\n",
    "            .rotate(rot)\n",
    "    )\n",
    "\n",
    "    # Cinematic effects\n",
    "    clip = clip.fl_image(lambda f: apply_motion_blur_to_frame(f))\n",
    "    clip = clip.fl_image(lambda f: add_film_grain(color_grade_frame(f)))\n",
    "\n",
    "    # Clean fades (no overlap)\n",
    "    clip = clip.fx(vfx.fadein, FADE_DURATION)\n",
    "    clip = clip.fx(vfx.fadeout, FADE_DURATION)\n",
    "\n",
    "    return clip\n",
    "\n",
    "\n",
    "print(\"\\nüé® Creating image clips...\")\n",
    "args = [(images[i], i) for i in range(len(images))]\n",
    "pool = ThreadPool(THREADS)\n",
    "clips = list(tqdm(pool.imap(build_clip_for_image, args), total=len(args)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# STEP 3 ‚Äî CONCATENATE CLIPS (NO OVERLAP)\n",
    "# ================================================================\n",
    "print(\"\\nüé¨ Concatenating...\")\n",
    "video_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# STEP 4 ‚Äî FINAL AUDIO (ONE PERFECT VOICE TRACK)\n",
    "# ================================================================\n",
    "print(\"\\nüéµ Adding voice + background music...\")\n",
    "\n",
    "full_voice = full_voice.set_duration(video_clip.duration)\n",
    "\n",
    "bg = AudioFileClip(bg_files[0]).volumex(0.1)\n",
    "if bg.duration < video_clip.duration:\n",
    "    loops = int(video_clip.duration // bg.duration) + 1\n",
    "    bg = concatenate_audioclips([bg] * loops).subclip(0, video_clip.duration)\n",
    "else:\n",
    "    bg = bg.subclip(0, video_clip.duration)\n",
    "\n",
    "final_audio = CompositeAudioClip([full_voice, bg]).set_duration(video_clip.duration)\n",
    "video_clip = video_clip.set_audio(final_audio)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# STEP 5 ‚Äî EXPORT VIDEO\n",
    "# ================================================================\n",
    "print(\"\\nüöÄ Rendering final video...\\n\")\n",
    "\n",
    "video_clip.write_videofile(\n",
    "    output_path,\n",
    "    fps=24,\n",
    "    codec=\"libx264\",\n",
    "    audio_codec=\"aac\",\n",
    "    preset=\"ultrafast\",\n",
    "    threads=8,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ DONE ‚Äî Saved at:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
